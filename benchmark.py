import json
import argparse
import time
import csv
import os
from datetime import datetime
from src.graph import app
from src.agents import redis_client
from src.vector_db import vector_store
import src.console as console
from rich.rule import Rule
from rich.table import Table
from collections import defaultdict

def run_benchmark(test_filepath: str, is_trained: bool):
    """
    ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìˆ˜í–‰í•˜ê³ , ì‹¤ì œ ì ìˆ˜ë¥¼ ì§‘ê³„í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    mode = "í•™ìŠµ í›„ (Trained)" if is_trained else "í•™ìŠµ ì „ (Untrained)"
    console.print_header(f"ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹œì‘: {mode}")

    if not is_trained:
        console.console.print("[bold yellow]ê²½ê³ : ëª¨ë“  DB(Redis, PostgreSQL)ì˜ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.[/bold yellow]")
        redis_client.flushall()
        console.console.print("ğŸ”´ Redis DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        try:
            vector_store.delete_collection()
            console.console.print("ğŸ”´ PostgreSQL ë²¡í„° DBê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            console.console.print(f"ğŸŸ¡ PostgreSQL ë²¡í„° DB ì´ˆê¸°í™” ì¤‘ ì°¸ê³ : {e}")
    else:
        console.console.print("ì‚¬ì „ í•™ìŠµëœ DBë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.")

    try:
        with open(test_filepath, 'r', encoding='utf-8') as f:
            test_cases = [json.loads(line) for line in f]
    except FileNotFoundError:
        console.console.print(f"[bold red]ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {test_filepath}[/bold red]")
        return

    # ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_filename = f"benchmark_results_{mode.replace(' ', '_')}_{timestamp}.csv"
    
    with open(results_filename, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        header = ['case_id', 'logical_consistency_score', 'legal_validity_score', 'social_consideration_score']
        writer.writerow(header)

        total_scores = defaultdict(float)
        total_runs = 0

        for i, case in enumerate(test_cases):
            case_id = case.get("caseId", "N/A")
            console.console.print(Rule(f"[bold]í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}/{len(test_cases)} ì‹¤í–‰ (ID: {case_id})[/bold]"))
            
            initial_state = {
                "case_file": f"ì›ê³  ì£¼ì¥: {case['plaintiff_statement']}\ní”¼ê³  ì£¼ì¥: {case['defendant_statement']}",
                "plaintiff_lawyer": "ì›ê³ ì¸¡ ë³€í˜¸ì‚¬",
                "defendant_lawyer": "í”¼ê³ ì¸¡ ë³€í˜¸ì‚¬",
            }

            final_event = None
            for event in app.stream(initial_state):
                if "__end__" in event:
                    final_event = event["__end__"]

            final_state = final_event or {}
            critique_scores = final_state.get('critique_scores', [])

            row_data = {'case_id': case_id}
            for item in critique_scores:
                criteria = item.get('criteria')
                score = item.get('score', 0)
                
                if "ë…¼ë¦¬ì " in criteria:
                    total_scores['ë…¼ë¦¬ì  ì¼ê´€ì„±'] += score
                    row_data['logical_consistency_score'] = score
                elif "ë²•ë¥ ì " in criteria:
                    total_scores['ë²•ë¥ ì  íƒ€ë‹¹ì„±'] += score
                    row_data['legal_validity_score'] = score
                elif "ì‚¬íšŒì " in criteria:
                    total_scores['ì‚¬íšŒì  ê°€ì¹˜ ê³ ë ¤'] += score
                    row_data['social_consideration_score'] = score
            
            writer.writerow([row_data.get(h, 'N/A') for h in header])
            total_runs += 1
            
            time.sleep(1)

    console.print_header(f"ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {mode}")
    console.console.print(f"ê²°ê³¼ê°€ [bold cyan]{results_filename}[/bold cyan] íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    table = Table(title="í‰ê·  ì ìˆ˜ (Pass ë¹„ìœ¨)")
    table.add_column("í‰ê°€ í•­ëª©", justify="right", style="cyan", no_wrap=True)
    table.add_column("í‰ê·  ì ìˆ˜ (%)", justify="center", style="magenta")

    if total_runs > 0:
        for criteria, total_score in total_scores.items():
            avg_score = (total_score / total_runs) * 100
            table.add_row(criteria, f"{avg_score:.2f}%")
    
    console.console.print(table)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ëª¨ì˜ ë²•ì • ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸")
    parser.add_argument('--mode', type=str, required=True, choices=['trained', 'untrained'],
                        help="'trained' ë˜ëŠ” 'untrained' ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    args = parser.parse_args()

    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    test_dataset_path = os.path.join(current_dir, "data", "test.jsonl")
    
    if args.mode == 'untrained':
        run_benchmark(test_dataset_path, is_trained=False)
    elif args.mode == 'trained':
        run_benchmark(test_dataset_path, is_trained=True)